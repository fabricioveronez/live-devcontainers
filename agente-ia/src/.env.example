# Configurações do modelo de IA
# Deixe como "proj" para usar o valor padrão hardcoded ou substitua pela sua chave da API
OPENAI_API_KEY=proj

# URL base do modelo (opcional - já configurado no código)
# MODEL_BASE_URL=http://model-runner.docker.internal/engines/v1
# MODEL_BASE_URL=http://localhost:12434

# Nome do modelo
MODEL_NAME=ai/gemma3:latest

# Temperatura do modelo (0.0 a 2.0)
MODEL_TEMPERATURE=1

# Timeout em milissegundos
MODEL_TIMEOUT=30000