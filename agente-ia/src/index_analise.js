import { config } from 'dotenv';
import { readFile } from 'fs/promises';
import { PromptTemplate } from '@langchain/core/prompts';
import { StringOutputParser } from '@langchain/core/output_parsers';
import { getChatModel } from './model/chat.js';

// Carrega as variÃ¡veis de ambiente do arquivo .env
config();

/**
 * Carrega o conteÃºdo de um arquivo de log
 * @param {string} filePath - Caminho para o arquivo de log
 * @returns {Promise<string>} ConteÃºdo do arquivo
 */
const loadLogFile = async (filePath) => {
    try {
        const content = await readFile(filePath, 'utf-8');
        return content;
    } catch (error) {
        throw new Error(`Erro ao ler o arquivo ${filePath}: ${error.message}`);
    }
};

/**
 * FunÃ§Ã£o principal que analisa logs usando o modelo de linguagem
 */
const main = async () => {
    try {
        console.log('ğŸ” Iniciando anÃ¡lise de logs com IA...\n');

        // Carrega o arquivo de log
        const logFilePath = './logs/nginx.log';
        console.log(`ğŸ“‚ Carregando arquivo: ${logFilePath}`);
        
        const logContent = await loadLogFile(logFilePath);
        console.log(`âœ… Arquivo carregado com sucesso! (${logContent.length} caracteres)\n`);

        // ObtÃ©m o modelo configurado
        const model = getChatModel();

        // Define o template do prompt para anÃ¡lise de logs
        const promptTemplate = PromptTemplate.fromTemplate(`
        VocÃª Ã© um assistente de IA que analisa logs de um sistema de monitoramento em ambiente Kubernetes.
        Analise os logs e responda a pergunta do usuÃ¡rio com base nas informaÃ§Ãµes contidas neles.

        Os logs sÃ£o os seguintes:
        {logs}

        Pergunta: {pergunta}
        `);

        // Cria a cadeia de processamento (chain)
        const outputParser = new StringOutputParser();
        const chain = promptTemplate.pipe(model).pipe(outputParser);

        console.log('ğŸ¤– Analisando logs...\n');

        // Gera a resposta
        const response = await chain.invoke({
            logs: logContent,
            // pergunta: 'Quais sÃ£o os principais erros encontrados nos logs?',
            pergunta: 'Analisando os logs, como estÃ¡ a execuÃ§Ã£o da aplicaÃ§Ã£o?',
        });

        console.log('ğŸ“‹ AnÃ¡lise dos Logs:');
        console.log('=' .repeat(60));
        console.log(response);
        console.log('=' .repeat(60));

    } catch (error) {
        if (error.code === 'ECONNREFUSED' || error.message.includes('connect')) {
            console.error('âŒ Erro de conexÃ£o: NÃ£o foi possÃ­vel conectar ao servidor do modelo.');
            console.error('ğŸ”§ Verifique se o serviÃ§o estÃ¡ rodando em localhost:11434 ou model-runner.docker.internal');
            console.error(`ğŸ“‹ Detalhes do erro: ${error.message}`);
        } else if (error.code === 'ENOENT') {
            console.error('âŒ Erro de arquivo: Arquivo de log nÃ£o encontrado.');
            console.error('ğŸ”§ Verifique se o arquivo ./logs/nginx.log existe.');
            console.error(`ğŸ“‹ Detalhes do erro: ${error.message}`);
        } else {
            console.error('ğŸ’¥ Erro inesperado:');
            console.error(error.message);
            console.error('\nğŸ” Stack trace:');
            console.error(error.stack);
        }
        process.exit(1);
    }
};

// Executa a funÃ§Ã£o principal
main().catch(console.error);